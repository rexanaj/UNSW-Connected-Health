{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise the workspace \n",
    "In order to deploy the workspace needs to initialised from the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "forced_interactive_auth = InteractiveLoginAuthentication(tenant_id=\"ca3fdb0e-9d68-48a6-8b66-2ae9e3cb6e2f\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config(path=\".azureml/config_ws.json\")\n",
    "print(ws.name, ws.resource_group, ws.location, sep ='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the Model to workspace\n",
    "Take the local file and register the model the azure workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace=ws, \n",
    "                    model_path=\"./ModelTrainedOnCambellSamples.h5\", \n",
    "                    model_name=\"af-detection-Model\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environment for deployment\n",
    "Creates the deployment environment with dependencies and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "environment = Environment(\"Local Deploy\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"inference-schema[numpy-support]\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"joblib\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"tensorflow==2.4.1\")\n",
    "environment.python.conda_dependencies.add_pip_package(\"scipy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_directory = \"source_dir\"\n",
    "\n",
    "os.makedirs(source_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create entry script for Webservice\n",
    "This script is used to initialise the ML service and handle its runtime behaviour when called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile source_dir/score.py\n",
    "import json\n",
    "import numpy as np \n",
    "from tensorflow.keras.models import load_model\n",
    "import process_ecg\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(\"af-detection-Model\")\n",
    "    model = load_model(model_path)\n",
    "\n",
    "def run(request):\n",
    "    try:\n",
    "        data = json.loads(request)\n",
    "        ecg_array = np.array(data)\n",
    "        processed = process_ecg.process(ecg_array)\n",
    "        result = model.predict(processed)\n",
    "        prediction = np.argmax(result)+1\n",
    "        reject = 0\n",
    "        if np.max(result[0]) < 0.97 and (np.max(result[0])-process_ecg.second_largest(result[0])) < 0.95:\n",
    "            reject = 1\n",
    "        return (int(Prediction), int(reject), model_name)\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return {'data' : error, \"message\" : 'unable to classify sample'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the configuration for inference\n",
    "This is to provide the webservice of knowledge of what environment to and what entry script to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(environment=environment, source_directory=source_directory, entry_script='score.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model as Local Webservice with Docker\n",
    "\n",
    "Using a docker container deploy the local service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice \n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
    "local_service = Model.deploy(ws, 'test', [model], inference_config, deployment_config)\n",
    "\n",
    "local_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Webservice using sample data\n",
    "Load Sample ecg signals and test the local deployment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "sample_ecg = np.fromfile(\"./source_dir/ecg_sample.dat\", dtype=np.dtype('<u2'))\n",
    "print(len(sample_ecg))\n",
    "sample_input = json.dumps({'data': sample_ecg.tolist()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_service.run(sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit score.py and reload the service if desired\n",
    "The following cells are for the editing of the score.py file and applying the changes to the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile source_dir/score.py\n",
    "import json\n",
    "import numpy as np \n",
    "from tensorflow.keras.models import load_model\n",
    "import process_ecg\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path((\"af-detection-Model\"))\n",
    "    model = load_model(model_path)\n",
    "\n",
    "def run(request):\n",
    "    try:\n",
    "        data = json.loads(request)\n",
    "        ecg_array = np.array(data['data'])\n",
    "        processed = process_ecg.process(ecg_array)\n",
    "        result = model.predict(processed)\n",
    "        prediction = np.argmax(result)+1\n",
    "        reject = 0\n",
    "        if np.max(result[0]) < 0.97 and (np.max(result[0])-process_ecg.second_largest(result[0])) < 0.95:\n",
    "           reject = 1\n",
    "        return (int(prediction), int(reject))\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return {'data' : error, \"message\" : 'unable to classify sample'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_service.reload()\n",
    "print(\"________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Model the Cloud Using AKS clusters, using same configuration as the Local deployment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aks_name = 'test-aks-1'\n",
    "\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found, existing cluster, use it.')\n",
    "except ComputeTargetException: \n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "    aks_target = ComputeTarget.create(workspace=ws, name=aks_name, provisioning_configuration = prov_config)\n",
    "if aks_target.get_status() != \"Succeeded\":\n",
    "    aks_target.wait_for_completion(show_output=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "ask_config = AksWebservice.deploy_configuration()\n",
    "%%time\n",
    "aks_service_name = 'aks-servive-1'\n",
    "aks_service = local_service.deploy_to_cloud(name=aks_service_name,deployment_config=ask_config, deployment_target=aks_target)\n",
    "aks_service.wait_for_deployment(show_output=True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "sample_ecg = np.fromfile(\"./source_dir/ecg_sample.dat\", dtype=np.dtype('<u2'))\n",
    "print(len(sample_ecg))\n",
    "sample_input = json.dumps({'data': sample_ecg.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service.run(sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the service once finished\n",
    "Once finished testing that the service works remove it to prevent additional costs accumulating over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_service.delete()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87c01b29e0f83b64e1d2542218f716ec1c5ef651a616015b7dec9eebee72d997"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ENG2600': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
